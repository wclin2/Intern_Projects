{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load library \n",
    "import pandas as pd, numpy as np\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = sqlCtx.read.format('com.databricks.spark.csv').options(header='true').load('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('vendor_id', 'string'),\n",
       " ('pickup_datetime', 'string'),\n",
       " ('dropoff_datetime', 'string'),\n",
       " ('passenger_count', 'string'),\n",
       " ('pickup_longitude', 'string'),\n",
       " ('pickup_latitude', 'string'),\n",
       " ('dropoff_longitude', 'string'),\n",
       " ('dropoff_latitude', 'string'),\n",
       " ('store_and_fwd_flag', 'string'),\n",
       " ('trip_duration', 'string')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"pickup_longitude\", df[\"pickup_longitude\"].cast('double'))\n",
    "df = df.withColumn(\"pickup_latitude\", df[\"pickup_latitude\"].cast('double'))\n",
    "df = df.withColumn(\"dropoff_longitude\", df[\"dropoff_longitude\"].cast('double'))\n",
    "df = df.withColumn(\"dropoff_latitude\", df[\"dropoff_latitude\"].cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+-------------------+---------------+-----------------+-----------------+------------------+------------------+------------------+-------------+\n",
      "|       id|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count| pickup_longitude|  pickup_latitude| dropoff_longitude|  dropoff_latitude|store_and_fwd_flag|trip_duration|\n",
      "+---------+---------+-------------------+-------------------+---------------+-----------------+-----------------+------------------+------------------+------------------+-------------+\n",
      "|id2875421|        2|2016-03-14 17:24:55|2016-03-14 17:32:30|              1|-73.9821548461914|40.76793670654297|-73.96463012695312|40.765602111816406|                 N|          455|\n",
      "+---------+---------+-------------------+-------------------+---------------+-----------------+-----------------+------------------+------------------+------------------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h_distance(lng1, lat1, lng2, lat2):\n",
    "    # km\n",
    "    # toRadians: Convert angles from degrees to radians\n",
    "    lat1 = toRadians(lat1)\n",
    "    lng1 = toRadians(lng1)\n",
    "    lat2 = toRadians(lat2) \n",
    "    lng2 = toRadians(lng2)\n",
    "    AVG_EARTH_RADIUS = 6371  #  km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = sin(lat * 0.5) ** 2 +\\\n",
    "    cos(lat1) *\\\n",
    "    cos(lat2) *\\\n",
    "    sin(lng * 0.5) ** 2\n",
    "    \n",
    "    h = 2 * AVG_EARTH_RADIUS * asin(sqrt(d))\n",
    "    return h\n",
    "\n",
    "# Manhattan distance\n",
    "def m_distance(lng1, lat1, lng2, lat2):\n",
    "    # km \n",
    "    a = h_distance(lat1, lng1, lat1, lng2)\n",
    "    b = h_distance(lat1, lng1, lat2, lng1)\n",
    "    return a + b\n",
    "\n",
    "# Convert time into hour-based type\n",
    "def get_time(x):\n",
    "    hour = udf(lambda s: datetime.strptime(s, '%Y-%m-%d %H:%M:%S').hour, IntegerType())\n",
    "    minute = udf(lambda s: datetime.strptime(s, '%Y-%m-%d %H:%M:%S').minute, IntegerType())\n",
    "    second = udf(lambda s: datetime.strptime(s, '%Y-%m-%d %H:%M:%S').second, IntegerType())\n",
    "    \n",
    "    h = hour(x)\n",
    "    m = minute(x)\n",
    "    s = second(x)\n",
    "    \n",
    "    time = h + m/60. + s/60./60.\n",
    "    \n",
    "    return time\n",
    "\n",
    "# Calculate the direction from start point to destination\n",
    "def get_direction(lng1, lat1, lng2, lat2):\n",
    "    # theta\n",
    "    AVG_EARTH_RADIUS = 6371  #  km\n",
    "    lng_delta_rad = toRadians(lng2 - lng1)\n",
    "    \n",
    "    lat1 = toRadians(lat1)\n",
    "    lng1 = toRadians(lng1)\n",
    "    lat2 = toRadians(lat2) \n",
    "    lng2 = toRadians(lng2)\n",
    "    \n",
    "    y = sin(lng_delta_rad) * cos(lat2)\n",
    "    x = cos(lat1) * sin(lat2) - sin(lat1) * cos(lat2) * cos(lng_delta_rad)\n",
    "    return toDegrees(atan2(y, x))\n",
    "\n",
    "\n",
    "parse_time_year = udf(lambda s: datetime.strptime(s, '%Y-%m-%d %H:%M:%S').year, IntegerType())\n",
    "parse_time_month = udf(lambda s: datetime.strptime(s, '%Y-%m-%d %H:%M:%S').month, IntegerType())\n",
    "parse_time_date = udf(lambda s: datetime.strptime(s, '%Y-%m-%d %H:%M:%S').day, IntegerType())\n",
    "parse_time_weekday = udf(lambda s: datetime.strptime(s, '%Y-%m-%d %H:%M:%S').weekday(), IntegerType())\n",
    "parse_time_hour = udf(lambda s: datetime.strptime(s, '%Y-%m-%d %H:%M:%S').hour, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df. is a column / df.select is a dataframe / df.select.rdd is rdd\n",
    "df = df.withColumn('pickup_year', parse_time_year(df.pickup_datetime))\n",
    "df = df.withColumn('pickup_month', parse_time_month(df.pickup_datetime))\n",
    "df = df.withColumn('pickup_date', parse_time_date(df.pickup_datetime))\n",
    "df = df.withColumn('pickup_weekday', parse_time_weekday(df.pickup_datetime))\n",
    "df = df.withColumn('pickup_hour', parse_time_hour(df.pickup_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('dropoff_year', parse_time_year(df.dropoff_datetime))\n",
    "df = df.withColumn('dropoff_month', parse_time_month(df.dropoff_datetime))\n",
    "df = df.withColumn('dropoff_date', parse_time_date(df.dropoff_datetime))\n",
    "df = df.withColumn('dropoff_weekday', parse_time_weekday(df.dropoff_datetime))\n",
    "df = df.withColumn('dropoff_hour', parse_time_hour(df.dropoff_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('H_distance', h_distance(df.pickup_longitude, df.pickup_latitude, df.dropoff_longitude, df.dropoff_latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('pickup_time(hour)', get_time(df.pickup_datetime))\n",
    "df = df.withColumn('dropoff_time(hour)', get_time(df.dropoff_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('m_distance', m_distance(df.pickup_longitude, df.pickup_latitude, df.dropoff_longitude, df.dropoff_latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('direction', get_direction(df.pickup_longitude, df.pickup_latitude, df.dropoff_longitude, df.dropoff_latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert category into numeric\n",
    "indexer = StringIndexer(inputCol='store_and_fwd_flag', outputCol='store_and_fwd_flag_dummy').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = indexer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+------------------+-------------------+------------------------+\n",
      "|dropoff_time(hour)| pickup_time(hour)|        H_distance|        m_distance|          direction|store_and_fwd_flag_dummy|\n",
      "+------------------+------------------+------------------+------------------+-------------------+------------------------+\n",
      "|17.541666666666668|17.415277777777778|1.4985207796469109|2.0202916912391164|  99.97019564714783|                     0.0|\n",
      "|0.9105555555555556|0.7263888888888889|1.8055071687958897|2.3474699407065938|-117.15376821269284|                     0.0|\n",
      "|             12.18|             11.59| 6.385098495253531| 4.577755595731812|-159.68016515404983|                     0.0|\n",
      "| 19.66111111111111|19.541944444444447|1.4854984227708028|0.6536447279420972|-172.73769967366482|                     0.0|\n",
      "|13.636111111111111|13.515277777777778|1.1885884593338851| 0.342564799686101|   179.473584610839|                     0.0|\n",
      "+------------------+------------------+------------------+------------------+-------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Briefly look at what we have done here\n",
    "df.select('dropoff_time(hour)', 'pickup_time(hour)', 'H_distance', 'm_distance', 'direction', 'store_and_fwd_flag_dummy').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = sqlCtx.read.format('com.databricks.spark.csv').options(header=True).load('central_park_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STATION',\n",
       " 'STATION_NAME',\n",
       " 'DATE',\n",
       " 'PRCP',\n",
       " 'SNWD',\n",
       " 'SNOW',\n",
       " 'TMAX',\n",
       " 'TMIN',\n",
       " 'AWND']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    DATE|\n",
      "+--------+\n",
      "|20090101|\n",
      "|20090102|\n",
      "|20090103|\n",
      "+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select('DATE').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parse_date_year = udf(lambda s: datetime.strptime(s, '%Y%m%d').year, IntegerType())\n",
    "parse_date_month = udf(lambda s: datetime.strptime(s, '%Y%m%d').month, IntegerType())\n",
    "parse_date_day = udf(lambda s: datetime.strptime(s, '%Y%m%d').day, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = weather.withColumn('year', parse_date_year(weather.DATE))\n",
    "weather = weather.withColumn('month', parse_date_month(weather.DATE))\n",
    "weather = weather.withColumn('day', parse_date_day(weather.DATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+---+\n",
      "|    DATE|year|month|day|\n",
      "+--------+----+-----+---+\n",
      "|20090101|2009|    1|  1|\n",
      "|20090102|2009|    1|  2|\n",
      "|20090103|2009|    1|  3|\n",
      "+--------+----+-----+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select('DATE', 'year', 'month', 'day').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since the taxi data only contains 2016\n",
    "temp = weather.filter(weather.year == 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = temp.drop('STATION', 'STATION_NAME', 'DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge two dataframe based on same year, month, day\n",
    "dff = df.join(temp, (df.pickup_year == temp.year) & (df.pickup_month == temp.month) & (df.pickup_date == temp.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-----+---+----+----+\n",
      "|    pickup_datetime|year|month|day|TMAX|TMIN|\n",
      "+-------------------+----+-----+---+----+----+\n",
      "|2016-03-14 17:24:55|2016|    3| 14|  51|  40|\n",
      "|2016-06-12 00:43:35|2016|    6| 12|  83|  62|\n",
      "|2016-01-19 11:35:24|2016|    1| 19|  28|  16|\n",
      "|2016-04-06 19:32:31|2016|    4|  6|  48|  30|\n",
      "|2016-03-26 13:30:55|2016|    3| 26|  55|  38|\n",
      "+-------------------+----+-----+---+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show what we've got here\n",
    "dff.select('pickup_datetime','year','month','day', 'TMAX', 'TMIN',).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+\n",
      "|pickup_weekday|count(vendor_id)|\n",
      "+--------------+----------------+\n",
      "|             1|          202749|\n",
      "|             6|          195366|\n",
      "|             3|          218574|\n",
      "|             5|          220868|\n",
      "|             4|          223533|\n",
      "|             2|          210136|\n",
      "|             0|          187418|\n",
      "+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simply show how many trips in each day\n",
    "a = dff.groupby('pickup_weekday').agg({'vendor_id':'count'})\n",
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
